
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <title>Probability — Interpretations, Axiomatic Theory, Measure and Simulation | Riccardo D'Annibale (corrected)</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <style>
    :root{
      --bg:#0f111a; --panel:#1a1c2b; --accent:#4CAF50; --muted:#cfd8cf;
      --glass: rgba(255,255,255,0.03);
    }
    *{box-sizing:border-box}
    html,body{height:100%;margin:0;font-family:'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
      background-color:var(--bg);color:#e0e0e0;line-height:1.7;padding:2rem;max-width:1200px;margin:auto}
    .topnav{display:flex;gap:1rem;margin-bottom:1rem}
    .topnav a{color:var(--accent);text-decoration:none;font-weight:700}
    .topnav a:hover{color:#66bb6a}
    h1,h2,h3{color:var(--accent)}
    h1{font-size:2.2rem;border-bottom:3px solid var(--accent);padding-bottom:0.3rem;margin:0 0 1rem}
    .card{background-color:var(--panel);border-left:5px solid var(--accent);border-radius:8px;padding:1.25rem;margin:1.25rem 0;box-shadow:0 6px 24px rgba(76,175,80,0.06)}
    .small{font-size:13px;color:var(--muted)}
    label{display:block;margin-top:10px;font-weight:700;color:#dfffe0}
    input, textarea, select{width:100%;padding:8px 10px;border-radius:6px;border:1px solid rgba(255,255,255,0.04);background:#0b0c10;color:#e6f4e6;font-size:14px}
    .controls{display:flex;gap:12px;margin-top:12px;flex-wrap:wrap}
    .code{background:#0b0c10;padding:12px;border-radius:6px;border:1px solid rgba(255,255,255,0.03);color:#dfeee0;overflow:auto;white-space:pre-wrap}
    .chartRow{display:flex;gap:12px;flex-wrap:wrap;margin-top:12px;padding-bottom:8px}
    .mainChart{flex:1 1 640px;background:#0f111a;padding:18px;border-radius:8px;border:1px solid rgba(255,255,255,0.03);min-width:320px;height:460px;box-sizing:border-box;overflow:visible}
    .sideChart{width:380px;min-width:280px;background:#0f111a;padding:18px;border-radius:8px;border:1px solid rgba(255,255,255,0.03);height:460px;box-sizing:border-box;overflow:visible}
    .mainChart canvas{width:100%;height:100%;display:block; box-sizing:border-box}
    .sideChart canvas{width:100%;height:100%;display:block; box-sizing:border-box}
    table{border-collapse:collapse;width:100%;margin-top:8px}
    th,td{border:1px solid rgba(255,255,255,0.06);padding:8px;text-align:left;color:#e7e7e7}
    th{background:rgba(76,175,80,0.06);color:#dfffe0}
    pre{background:#0b0c10;color:#dfeee0;padding:12px;border-radius:6px;overflow:auto;border:1px solid rgba(255,255,255,0.03)}
    button{padding:8px 12px;border-radius:6px;background:var(--accent);border:0;color:#072;font-weight:700;cursor:pointer}
    button.secondary{background:transparent;border:1px solid rgba(255,255,255,0.04);color:var(--muted);font-weight:700}
    .muted{color:var(--muted)}
    @media(max-width:900px){ .mainChart,.sideChart{height:320px} .mainChart{flex-basis:100%} .sideChart{width:100%} .controls{flex-direction:column} }

    /* MathJax styling: make math inherit page color on dark theme */
    .mjx-chtml { color: inherit !important; font-size:1.05rem !important; line-height:1.28 !important; white-space: normal !important; }
    .display-equation { background: rgba(255,255,255,0.02); padding:12px 14px; border-radius:6px; border:1px solid rgba(255,255,255,0.03); margin:12px 0; font-size:1.05rem; overflow:auto; }

    /* Fix: paragraph width — remove the 90ch cap so paragraphs can occupy full card width */
    p { max-width: 100%; text-align:justify; margin: 0 0 1rem; }
    p.lead { color:#e9f6e9; font-size:1.02rem; }
    .chartLegend { margin-top:8px; color:#e6f4e6; font-size:13px; }
    .inline-math { background: rgba(255,255,255,0.02); padding:0 3px; border-radius:3px; }
  </style>

  <script>
    /* MathJax: use \(..\) and \[..\], process after DOMContentLoaded */
    window.MathJax = {
      loader: { load: ['input/tex', 'output/chtml', 'ui/menu'] },
      tex: {
        packages: {'[+]': ['ams','amsmath','amssymb']},
        inlineMath: [['\\(', '\\)']],
        displayMath: [['\\[', '\\]']],
        processEscapes: true
      },
      chtml: { scale: 1.12 },
      startup: { typeset: false }
    };
  </script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/chart.js@4"></script>
</head>
<body>
  <header class="topnav" role="navigation" aria-label="Main navigation">
    <a href="/">Home</a>
    <a href="/about/">About</a>
  </header>

  <main>

    <article class="card">
      <h1>Probability — Interpretations, axiomatic theory, measure and simulation</h1>
    </article>

<article class="card" id="interpretations">
  <h2>1. Interpretations of probability</h2>

  <p class="lead">
    The word “probability” takes on different meanings depending on context: random games,
    physical phenomena, data analysis, statistical inference. Modern axiomatic theory
    provides the mathematical framework that allows these readings to coexist without
    contradictions, interpreting them as different ways to build the outcome space,
    events and the probability measure.
  </p>

  <h3>1.1 Classical interpretation (Laplace)</h3>
  <p>
    This is the original historical form of probability and is based on the idea of symmetry:
    when elementary outcomes are finite and equally likely, uncertainty is represented by the
    ratio between “favorable cases” and “possible cases”. Think of rolling a die or
    drawing a card from a well-shuffled deck: no outcome is privileged, and it is precisely
    this symmetry that yields the notion of probability.
  </p>

  <h3>1.2 Frequentist interpretation</h3>
  <p>
    Here probability emerges as an observable property of a repeatable process. One
    considers a large number of identical repetitions of the experiment and observes the
    relative frequency of the event: if this stabilizes around a value, that is its
    probability. The idea is intrinsically empirical, based on long-run behavior of data sequences.
  </p>

  <h3>1.3 Bayesian interpretation</h3>
  <p>
    According to the Bayesian interpretation, probability represents a coherent degree of belief
    of a rational agent. Uncertainty is modeled using probability distributions and each new
    piece of information updates those beliefs via Bayes' theorem. This allows assigning
    probabilities not only to events but also to the model parameters themselves.
  </p>

  <h3>1.4 Geometric and measure-based interpretation</h3>
  <p>
    The geometric interpretation arises from the need to treat continuous phenomena. A point
    chosen “at random” in an interval cannot be modeled through equally likely cases: one
    needs a measure that assigns consistent weights to parts of the space. Probability thus
    becomes a normalized measure (for example the Lebesgue measure) applied to measurable sets.
  </p>

  <h3>1.5 Propensity interpretation (physical)</h3>
  <p>
    In some areas of physics and the natural sciences, probability is interpreted as
    an objective tendency of a system to produce certain outcomes. Radioactive decay, for
    instance, is described by a “propensity” for the event to occur within a time interval.
    The uncertainty does not stem from symmetry or ignorance, but is a structural feature
    of the phenomenon.
  </p>

  <h3>1.6 How the axiomatic approach unifies these interpretations</h3>
  <p>
    Despite their diversity, all interpretations of probability lead to a probability function
    that satisfies the same fundamental properties: non-negativity, normalization and σ-additivity
    (Kolmogorov's axioms). The axiomatic approach allows treating them as different ways of
    constructing the triplet:
  </p>

  <div class="display-equation">\[
    (\Omega, \mathcal{F}, P)
  \]</div>

  <h4>Kolmogorov axioms (summary)</h4>
  <ol>
    <li><strong>Non-negativity:</strong> for every event \(A \in \mathcal{F}\), \(P(A) \ge 0\).</li>
    <li><strong>Normalization:</strong> \(P(\Omega) = 1\).</li>
    <li><strong>σ-additivity:</strong> for every sequence of disjoint events \(A_1, A_2, \dots \in \mathcal{F}\),
    \[\; P\Big(\bigcup_{i} A_i\Big) = \sum_i P(A_i).\]</li>
  </ol>

</article>

<article class="card" id="measure">
  <h2>2. Relationship between probability and measure theory</h2>

  <p>Formally, <em>probability</em> is a <em>measure</em> with total mass 1. This step allows the use of tools from mathematical analysis (integrals, convergences) in probability theory.</p>

  <h3>2.1 Probability space</h3>
  <p>The fundamental structure is the triple:</p>
  <div class="display-equation">\[
    (\Omega, \mathcal{F}, P)
  \]</div>
  <ul>
    <li><strong>\(\Omega\)</strong> = sample space;</li>
    <li><strong>\(\mathcal{F}\)</strong> = σ-algebra, closed under countable unions and complements;</li>
    <li><strong>\(P: \mathcal{F} \to [0,1]\)</strong> = measure with <strong>\(P(\Omega) = 1\)</strong> and σ-additivity.</li>
  </ul>

  <h3>2.2 Random variables as measurable functions</h3>
  <p>A random variable <strong>\(X\)</strong> is a measurable function:</p>
  <div class="display-equation">\[
    X : (\Omega, \mathcal{F}) \to (\mathbb{R}, \mathcal{B})
  \]</div>

  <h3>2.3 Expectations = Lebesgue integrals</h3>
  <div class="display-equation">\[
    \mathbb{E}[X] = \int_\Omega X(\omega)\, P(d\omega) = \int_{\mathbb{R}} x\, P_X(dx).
  \]</div>

  <h3>2.4 Stochastic processes and product measurability</h3>
  <p>A stochastic process <strong>\(\{X_t\}_{t \in T}\)</strong> is a family of random variables. Finite-dimensional joint distributions define the law of the process. Properties such as independence, stationarity and others are formulated in terms of marginal and joint measures. Measure theory provides the rigorous language to describe these concepts.</p>
</article>

<article class="card" id="derivations">
  <h2>3. Formal derivations from the axioms</h2>

  <h3>3.1 Subadditivity (Boole's inequality)</h3>

  <p><strong>Statement.</strong> For every sequence of events 
     <span class="inline-math">\(A_1, A_2, \dots \in \mathcal{F}\)</span>, Boole's inequality holds:</p>

  <div class="display-equation">
    \[
      P\Big(\bigcup_{i=1}^{\infty} A_i\Big) \le \sum_{i=1}^{\infty} P(A_i)
    \]
  </div>

  <p><strong>Proof.</strong> Define a sequence of disjoint sets:</p>

  <div class="display-equation">
    \[
      B_1 = A_1, \qquad B_n = A_n \setminus \bigcup_{i=1}^{n-1} A_i, \quad n \ge 2
    \]
  </div>

  <p>By construction, the \(B_n\) are disjoint and satisfy:</p>

  <div class="display-equation">
    \[
      \bigcup_{i=1}^{\infty} B_i = \bigcup_{i=1}^{\infty} A_i
    \]
  </div>

  <p>Applying σ-additivity of probability, we obtain:</p>

  <div class="display-equation">
    \[
      P\Big(\bigcup_{i=1}^{\infty} A_i\Big) = \sum_{i=1}^{\infty} P(B_i)
    \]
  </div>

  <p>Since \(B_i \subseteq A_i\), it follows that \(P(B_i) \le P(A_i)\). Summing over all indices gives the desired inequality.</p>

  <h3>3.2 Inclusion–exclusion principle</h3>

  <div class="display-equation">
    \[
      \boxed{
        P\!\left(\bigcup_{i=1}^n A_i\right)
        = \sum_{k=1}^n (-1)^{k+1}
          \sum_{1 \le i_1 < \cdots < i_k \le n}
          P\!\left(A_{i_1} \cap \cdots \cap A_{i_k}\right)
      }
    \]
  </div>

  <p>
    <strong>Proof via indicator variables.</strong>
    Let \(1_A(\omega)\) be the indicator of \(A\). For every \(\omega\) the following pointwise identity holds:
  </p>

  <div class="display-equation">
    \[
      1_{\;\bigcup_{i=1}^n A_i}(\omega)
      = \sum_{k=1}^n (-1)^{k+1}
        \sum_{1 \le i_1 < \cdots < i_k \le n}
        1_{A_{i_1} \cap \cdots \cap A_{i_k}}(\omega).
    \]
  </div>

  <p>If \(r=r(\omega)\) is the number of events \(A_i\) that contain \(\omega\), the right-hand side is
  \(\sum_{k=1}^r (-1)^{k+1}\binom{r}{k}\), which equals 1 when \(r\ge1\) and 0 when \(r=0\). Integrating both sides with respect to \(P\) yields the inclusion–exclusion formula for probabilities.</p>

  <p>The formula is exact but in practice is rarely used for large \(n\) due to the combinatorial growth of terms; bounds (Boole / Bonferroni) or truncations of the alternating series are preferred.</p>
</article>

<article class="card" id="simulation-theory">
  <h2>4. Simulation and analysis: approximating a uniform counting process</h2>

  <p class="lead">Now we bring the formalism into practice: we want to simulate a counting process on <span class="inline-math">\([0,T]\)</span> where events occur independently and uniformly with mean rate <span class="inline-math">\(\lambda\)</span>.</p>

<h3>4.1 Numerical scheme (binomial discretization)</h3>
<p>
  Split <span class="inline-math">\([0,T]\)</span> into
  <span class="inline-math">\(n\)</span> subintervals of length
  <span class="inline-math">\(\Delta t = T/n\)</span>.
  In each subinterval we generate an event with probability
  <span class="inline-math">\(p = \lambda \Delta t = \lambda T / n\)</span>.
  (When <span class="inline-math">\(T = 1\)</span>, this reduces to
  <span class="inline-math">\(p = \lambda / n\)</span>.)
  The total is the sum of <span class="inline-math">\(n\)</span> independent
  Bernoulli trials, thus:
</p>
<div class="display-equation">\[
  X_n \sim \operatorname{Bin}(n,p),\quad
  E[X_n] = np,\ \mathrm{Var}(X_n) = np(1-p).
\]</div>


  <h3>4.2 Why Binomial → Poisson (law of rare events)</h3>
  <p>For fixed <span class="inline-math">\(k\ge0\)</span>, the binomial pmf is</p>
  <div class="display-equation">\[
    P(X_n=k)=\binom{n}{k} \left(\frac{\lambda T}{n}\right)^k
          \left(1-\frac{\lambda T}{n}\right)^{n-k}.
  \]</div>
  <p>As <span class="inline-math">\(n\to\infty\)</span> one obtains the pmf of <span class="inline-math">\(\operatorname{Poisson}(\lambda T)\)</span>.</p>

  <h3>4.3 Properties of the limiting process</h3>
  <ul>
    <li><strong>Independent and stationary increments</strong>: counts on disjoint intervals are independent; the count in an interval of length <span class="inline-math">\(\tau\)</span> is <span class="inline-math">\(\operatorname{Poisson}(\lambda\tau)\)</span>.</li>
    <li><strong>Inter-arrivals</strong>: the times between successive events are i.i.d. <span class="inline-math">\(\operatorname{Exp}(\lambda)\)</span>, with the memoryless property.</li>
    <li><strong>Simplicity</strong>: zero probability of having two events at the same instant.</li>
    <li><strong>Additivity</strong>: the sum of independent Poisson streams is still Poisson with rate equal to the sum of rates.</li>
  </ul>

  <h3>4.4 Interpretation and role of <span class="inline-math">\(\lambda\)</span></h3>
  <p><span class="inline-math">\(\lambda\)</span> is the intensity (rate) of the process: <span class="inline-math">\(E[N(t)]=\lambda t\)</span>. <span class="inline-math">\(1/\lambda\)</span> is the mean time between events. In practice, choosing <span class="inline-math">\(\lambda\)</span> fixes the average rhythm of events; if <span class="inline-math">\(\lambda\)</span> depends on time one gets a non-homogeneous Poisson process and simulation requires more advanced methods (thinning).</p>

  <h3>4.5 Numerical examples and recommendations</h3>
  <p>For good approximation choose <span class="inline-math">p=\lambda\Delta t \ll 1</span> (for example <span class="inline-math">p&lt;10^{-2}</span>). With <span class="inline-math">\lambda=3,\, T=1,\, n=5000</span> one gets <span class="inline-math">p=0.0006</span>, which is very small and ensures fast convergence.</p>

  <p>More efficient and accurate alternative methods:</p>
  <ol>
    <li><strong>Inter-arrival method</strong>: generate event times as sums of <span class="inline-math">\(\operatorname{Exp}(\lambda)\)</span> variables until exceeding <span class="inline-math">\(T\)</span>. It is exact and efficient when the average number of events <span class="inline-math">\(\lambda T\)</span> is not too large.</li>
    <li><strong>Direct count sampling</strong>: for each trajectory sample <span class="inline-math">\(N(T)\sim\operatorname{Poisson}(\lambda T)\)</span>. If times are needed, place the <span class="inline-math">\(N(T)\)</span> points i.i.d. uniform on <span class="inline-math">\([0,T]\)</span> and sort them.</li>
  </ol>
</article>

<article class="card" id="sim-ui">
  <h2>5. Interactive simulator</h2>

  <div style="display:flex;gap:12px;flex-wrap:wrap">
    <div style="flex:1;min-width:160px"><label for="mTraj">m — number of trajectories</label><input id="mTraj" type="number" value="2000" min="1" max="20000"></div>
    <div style="flex:1;min-width:160px"><label for="nSteps">n — subintervals (for discretization)</label><input id="nSteps" type="number" value="5000" min="10" max="1000000"></div>
    <div style="flex:1;min-width:160px"><label for="lambdaRate">λ — mean rate</label><input id="lambdaRate" type="number" step="0.1" value="3" min="0" max="1000"></div>
    <div style="flex:1;min-width:120px"><label for="Tdur">T — duration</label><input id="Tdur" type="number" step="0.1" value="1" min="0.01" max="100"></div>
  </div>

  <div class="controls" role="toolbar" aria-label="Simulation controls">
    <button id="runSim">Run simulation (Binomial discretization)</button>
    <button id="runInter">Run simulation (exponential inter-arrivals)</button>
    <button id="runPoisson">Run simulation (direct Poisson sampling)</button>
    <button id="clearBtn" class="secondary">Clear</button>
    <button id="exportCSV" class="secondary">Export CSV</button>
    <label class="small">Show first k trajectories</label>
    <input id="kShow" type="number" value="30" min="1" style="width:80px">
    <div id="status" class="small muted" style="margin-left:8px">Ready</div>
  </div>

  <div class="chartRow" style="margin-top:12px">
    <div class="mainChart" id="chartTrajWrap">
      <canvas id="trajCanvas" aria-label="Trajectories N(t)"></canvas>
      <div class="small chartLegend">Trajectories <span class="inline-math">\(N(t)\)</span> — dashed: expected value <span class="inline-math">\( \lambda t \)</span></div>
    </div>

    <div class="sideChart" id="chartHistWrap">
      <canvas id="histCanvas" aria-label="Histogram of final counts"></canvas>
      <div class="small chartLegend">Histogram of <span class="inline-math">\(N(T)\)</span> with superimposed Poisson pmf</div>
    </div>
  </div>

  <div class="chartRow" style="margin-top:12px">
    <div class="mainChart" style="height:320px">
      <canvas id="iaCanvas" aria-label="Inter-arrival histogram"></canvas>
      <div class="small chartLegend">Inter-arrival histogram with superimposed exponential density</div>
    </div>
  </div>

  <pre id="report" class="code" aria-live="polite">Results and statistics will appear here.</pre>
</article>

<article class="card">
  <h2>6. Final remarks </h2>
  <p>The axiomatic approach provides the rigorous framework in which all interpretations find their place; measure theory is the tool to define expectations and convergences; binomial discretization is a valid way to approximate the Poisson process when events are “rare” in every subinterval. For further reading:</p>
  <ol>
    <li>A. N. Kolmogorov — <em>Foundations of the Theory of Probability</em>.</li>
    <li>P. Billingsley — <em>Probability and Measure</em>.</li>
    <li>R. Durrett — <em>Probability: Theory and Examples</em>.</li>
    <li>Kingman — <em>Poisson Processes</em>.</li>
  </ol>
</article>

<footer class="small" style="margin-top:18px">© 2025 Riccardo D'Annibale</footer>
  </main>

  <script>
    // Typeset MathJax after content load
    document.addEventListener('DOMContentLoaded', () => {
      if(window.MathJax && MathJax.typesetPromise){
        MathJax.typesetPromise().catch(e=>console.error('MathJax typeset error:', e));
      }
    });
  </script>

  <!-- SIMULATOR SCRIPT: identical to tested version (included here for completeness) -->
  <script>
  const $ = id => document.getElementById(id);
  let trajChart=null, histChart=null, iaChart=null, lastResult=null;

  function initCharts(){
    if(trajChart) trajChart.destroy();
    if(histChart) histChart.destroy();
    if(iaChart) iaChart.destroy();

    const defaultOptions = {
      responsive:true,
      maintainAspectRatio:false,
      animation:false,
      layout: { padding: { left: 12, right: 12, top: 12, bottom: 12 } },
      plugins: {
        legend: { labels: { color:'#e6f4e6', boxWidth:12, padding:8 }, position: 'top' },
        tooltip: { mode: 'index', intersect: false }
      },
      scales: {
        x: { ticks:{ color:'#e0e0e0', maxRotation:0, autoSkip:true }, grid:{ color:'rgba(255,255,255,0.03)' } },
        y: { ticks:{ color:'#e0e0e0' }, grid:{ color:'rgba(255,255,255,0.03)' } }
      }
    };

    const ctxT = $('trajCanvas').getContext('2d');
    trajChart = new Chart(ctxT, {
      type: 'line',
      data: { labels: [], datasets: [] },
      options: Object.assign({}, defaultOptions, {
        scales: { x: defaultOptions.scales.x, y: Object.assign({}, defaultOptions.scales.y, { title:{ display:true, text:'Cumulative count N(t)', color:'#e0e0e0' } }) }
      })
    });

    const ctxH = $('histCanvas').getContext('2d');
    histChart = new Chart(ctxH, {
      type: 'bar',
      data: { labels: [], datasets: [] },
      options: Object.assign({}, defaultOptions, {
        scales: { x: Object.assign({}, defaultOptions.scales.x, { title:{ display:true, text:'k (count)', color:'#e0e0e0' } }), y: Object.assign({}, defaultOptions.scales.y, { title:{ display:true, text:'Frequency', color:'#e0e0e0' } }) }
      })
    });

    const ctxIA = $('iaCanvas').getContext('2d');
    iaChart = new Chart(ctxIA, {
      type: 'bar',
      data: { labels: [], datasets: [] },
      options: Object.assign({}, defaultOptions, {
        scales: { x: Object.assign({}, defaultOptions.scales.x, { title:{ display:true, text:'Inter-arrival (s)', color:'#e0e0e0' } }), y: Object.assign({}, defaultOptions.scales.y, { title:{ display:true, text:'Frequency', color:'#e0e0e0' } }) }
      })
    });
  }
  initCharts();

  const palette = ['#4CAF50','#66bb6a','#8BC34A','#CDDC39','#FFC107','#FF9800','#FF5722','#E91E63','#9C27B0','#3F51B5'];

  function lnGamma(z){
    const g = 7;
    const p = [0.99999999999980993,676.5203681218851,-1259.1392167224028,771.32342877765313,-176.61502916214059,12.507343278686905,-0.13857109526572012,9.9843695780195716e-6,1.5056327351493116e-7];
    if(z < 0.5) {
      return Math.log(Math.PI) - Math.log(Math.sin(Math.PI*z)) - lnGamma(1 - z);
    } else {
      z -= 1;
      let x = p[0];
      for(let i=1;i<p.length;i++) x += p[i]/(z + i);
      const t = z + g + 0.5;
      return 0.5*Math.log(2*Math.PI) + (z + 0.5)*Math.log(t) - t + Math.log(x) - Math.log(z+1);
    }
  }

  function gammainc_series(a,x){
    const EPS = 1e-12;
    let sum = 1/a;
    let term = sum;
    let n = 1;
    while(Math.abs(term) > EPS * Math.abs(sum)){
      term *= x/(a + n);
      sum += term;
      n++;
      if(n>10000) break;
    }
    const logGammaA = lnGamma(a);
    const pref = Math.exp(a*Math.log(x) - x - logGammaA);
    return pref * sum;
  }

  function gammainc_cf(a,x){
    const MAXIT = 10000;
    const EPS = 1e-12;
    let b = x + 1 - a;
    let c = 1 / 1e-30;
    let d = 1 / b;
    let h = d;
    for(let i=1;i<MAXIT;i++){
      const an = -i*(i - a);
      b += 2;
      d = an*d + b;
      if(Math.abs(d) < 1e-30) d = 1e-30;
      c = b + an/c;
      if(Math.abs(c) < 1e-30) c = 1e-30;
      d = 1/d;
      const delta = d*c;
      h *= delta;
      if(Math.abs(delta - 1) < EPS) break;
    }
    const logGammaA = lnGamma(a);
    return Math.exp(a*Math.log(x) - x - logGammaA) * h;
  }

  function regularized_lower_gamma(a,x){
    if(x < 0 || a <= 0) return NaN;
    if(x === 0) return 0;
    if(x < a + 1) {
      return gammainc_series(a,x);
    } else {
      const Q = gammainc_cf(a,x);
      return 1 - Q;
    }
  }

  function chi2_cdf(x, k){
    if(x < 0) return 0;
    return regularized_lower_gamma(k/2, x/2);
  }

  function chi2_pvalue(chi2, df){
    const cdf = chi2_cdf(chi2, df);
    return 1 - cdf;
  }

  function poissonPmfArray(mu, maxk){
    const a = new Array(maxk+1);
    a[0] = Math.exp(-mu);
    for(let k=1;k<=maxk;k++) a[k] = a[k-1] * mu / k;
    return a;
  }

  function computeChiSquare(obsCounts, expCounts){
    const obs = obsCounts.slice();
    const exp = expCounts.slice();
    while(exp.length>1 && exp[exp.length-1] < 5){
      exp[exp.length-2] += exp.pop();
      obs[obs.length-2] += obs.pop();
    }
    while(exp.length>1 && exp[0] < 5){
      exp[1] += exp.shift();
      obs[1] += obs.shift();
    }
    let chi2=0, k=0;
    for(let i=0;i<exp.length;i++){
      if(exp[i]>0){ chi2 += Math.pow(obs[i]-exp[i],2)/exp[i]; k++; }
    }
    const df_known = Math.max(0, k-1);
    const df_est = Math.max(0, k-2);
    const pvalue_known = chi2_pvalue(chi2, df_known);
    const pvalue_est = chi2_pvalue(chi2, df_est);
    return { chi2, k, df_known, df_est, pvalue_known, pvalue_est };
  }

  function klDivergence(empCounts, theoProbs){
    const m = empCounts.reduce((a,b)=>a+b,0);
    const eps = 1e-12;
    let D=0;
    for(let i=0;i<empCounts.length;i++){
      const p = empCounts[i]/m;
      const q = theoProbs[i] || eps;
      if(p>0) D += p * Math.log(p/(q+eps));
    }
    return D;
  }

  function simulate_discretization(m,n,lambda,T,kShow){
    const dt = T / n;
    const p = Math.min(1, lambda * dt);
    const trajectories = Array.from({length: Math.min(kShow,m)}, ()=> new Float32Array(n));
    const finalCounts = new Uint32Array(m);
    const interarrivals = [];

    for(let i=0;i<m;i++){
      let cum = 0;
      let lastTime = null;
      for(let t=0;t<n;t++){
        if(Math.random() < p){
          cum++;
          const time = (t + Math.random())*dt;
          if(lastTime !== null){ interarrivals.push(time - lastTime); }
          lastTime = time;
        }
        if(i < trajectories.length) trajectories[i][t] = cum;
      }
      finalCounts[i] = cum;
    }

    return { trajectories, finalCounts: Array.from(finalCounts), interarrivals };
  }

  function simulate_interarrivals(m,lambda,T,kShow){
    const trajectories = [];
    const finalCounts = new Array(m);
    const interarrivalsAll = [];
    for(let i=0;i<m;i++){
      let t = 0; let cum = 0; const times = [];
      while(true){
        const u = Math.random();
        if(u === 0) continue;
        const tau = -Math.log(u)/Math.max(1e-12,lambda);
        t += tau;
        if(t > T) break;
        cum++;
        times.push(t);
      }
      trajectories.push(times.slice(0,kShow));
      finalCounts[i] = cum;
      for(let j=1;j<times.length;j++) interarrivalsAll.push(times[j]-times[j-1]);
    }
    return { trajectories, finalCounts, interarrivals: interarrivalsAll };
  }

  function simulate_direct_poisson(m,lambda,T,kShow){
    const mu = lambda * T;
    const finalCounts = new Array(m);
    const interarrivalsAll = [];
    const trajectoriesTimes = [];
    for(let i=0;i<m;i++){
      const L = Math.exp(-mu);
      let k = 0; let p = 1;
      while(p > L){ p *= Math.random(); k++; }
      k = Math.max(0, k-1);
      finalCounts[i] = k;
      if(k>0){
        const times = Array.from({length:k}, ()=> Math.random()*T).sort((a,b)=>a-b);
        trajectoriesTimes.push(times.slice(0,kShow));
        for(let j=1;j<times.length;j++) interarrivalsAll.push(times[j]-times[j-1]);
      } else trajectoriesTimes.push([]);
    }
    return { trajectories: trajectoriesTimes, finalCounts, interarrivals: interarrivalsAll };
  }

  $('runSim').addEventListener('click', ()=>{
    try{
      const m = Math.max(1, Math.min(20000, Number($('mTraj').value)||2000));
      const n = Math.max(1, Math.min(1000000, Number($('nSteps').value)||5000));
      let lambda = Number($('lambdaRate').value); if(isNaN(lambda)||lambda<0) lambda=1;
      let T = Number($('Tdur').value); if(isNaN(T)||T<=0) T=1;
      const kShow = Math.max(1, Math.min(m, Number($('kShow').value)||30));
      $('status').textContent = 'Running simulation (discretization)...';

      if(m*n > 6e7){
        if(!confirm('Warning: m*n = ' + (m*n) + '. Proceeding may be slow.')){ $('status').textContent='Canceled'; return; }
      }

      const res = simulate_discretization(m,n,lambda,T,kShow);
      processAndRender(res, m, n, lambda, T);
    }catch(err){
      $('status').textContent = 'Error: ' + String(err);
      console.error(err);
    }
  });

  $('runInter').addEventListener('click', ()=>{
    try{
      const m = Math.max(1, Math.min(20000, Number($('mTraj').value)||2000));
      let lambda = Number($('lambdaRate').value); if(isNaN(lambda)||lambda<=0) lambda=1;
      let T = Number($('Tdur').value); if(isNaN(T)||T<=0) T=1;
      const kShow = Math.max(1, Math.min(m, Number($('kShow').value)||30));
      $('status').textContent = 'Running simulation (inter-arrivals)...';

      const res = simulate_interarrivals(m,lambda,T,kShow);
      processAndRender(res, m, null, lambda, T);
    }catch(err){
      $('status').textContent = 'Error: ' + String(err);
      console.error(err);
    }
  });

  $('runPoisson').addEventListener('click', ()=>{
    try{
      const m = Math.max(1, Math.min(20000, Number($('mTraj').value)||2000));
      let lambda = Number($('lambdaRate').value); if(isNaN(lambda)||lambda<0) lambda=1;
      let T = Number($('Tdur').value); if(isNaN(T)||T<=0) T=1;
      const kShow = Math.max(1, Math.min(m, Number($('kShow').value)||30));
      $('status').textContent = 'Running simulation (direct Poisson)...';

      const res = simulate_direct_poisson(m,lambda,T,kShow);
      processAndRender(res, m, null, lambda, T);
    }catch(err){
      $('status').textContent = 'Error: ' + String(err);
      console.error(err);
    }
  });

  $('clearBtn').addEventListener('click', ()=>{ initCharts(); $('report').textContent='Charts cleared.'; $('status').textContent='Ready'; lastResult=null; });

  $('exportCSV').addEventListener('click', ()=>{
    if(!lastResult){ alert('Run a simulation first to export.'); return; }
    const { m,n,lambda,T, finalCounts } = lastResult;
    let csv = 'trajectory_index,N_T\n';
    for(let i=0;i<finalCounts.length;i++) csv += (i+1) + ',' + finalCounts[i] + '\n';
    const blob = new Blob([csv], { type: 'text/csv;charset=utf-8;' });
    const url = URL.createObjectURL(blob);
    const a = document.createElement('a'); a.href = url; a.download = 'poisson_m' + m + '_n' + (n||'na') + '_lambda' + lambda.toFixed(2) + '_T' + T + '.csv'; document.body.appendChild(a); a.click(); a.remove(); URL.revokeObjectURL(url);
  });

  window.addEventListener('resize', ()=>{ if(trajChart) trajChart.resize(); if(histChart) histChart.resize(); if(iaChart) iaChart.resize(); });

  function processAndRender(res, m, n, lambda, T){
    const { trajectories, finalCounts, interarrivals } = res;
    const mu = lambda * T;

    if(n){
      const dt = T / n;
      const labels = Array.from({length:n}, (_,i)=> ((i+1)*dt).toFixed(3));
      trajChart.data.labels = labels;
      trajChart.data.datasets = [];
      for(let i=0;i<Math.min(trajectories.length, Number($('kShow').value));i++){
        trajChart.data.datasets.push({ label: 'traj ' + (i+1), data: Array.from(trajectories[i]), borderColor: palette[i % palette.length], borderWidth: 1.2, pointRadius: 0, fill: false });
      }
      trajChart.data.datasets.push({ label: 'expected value λt', data: labels.map((_,idx)=> lambda * ((idx+1)*dt)), borderColor: '#ffffff', borderDash: [6,6], borderWidth: 1.2, pointRadius: 0, fill: false });
      trajChart.update();
    } else {
      trajChart.data.labels = [];
      trajChart.data.datasets = [];
      trajChart.update();
    }

    const msize = finalCounts.length;
    const maxObserved = Math.max(...finalCounts);
    const maxk = Math.max( Math.min(200, Math.ceil(Math.sqrt(msize))+10), maxObserved );
    const bins = new Array(maxk+1).fill(0);
    for(let i=0;i<msize;i++){ const k = Math.min(maxk, finalCounts[i]); bins[k]++; }
    const binLabels = bins.map((_,i)=> String(i));

    const pmf = poissonPmfArray(mu, maxk);
    const pmfScaled = pmf.map(v=> v * msize);

    histChart.data.labels = binLabels;
    histChart.data.datasets = [ { label:'observed counts', data: bins, backgroundColor:'rgba(76,175,80,0.6)' }, { type:'line', label:'Poisson pmf (scale)', data: pmfScaled, borderColor:'#ffffff', borderWidth:1.6, pointRadius:2, fill:false, tension:0.2 } ];
    histChart.update();

    const iaSample = interarrivals.slice(0, Math.min(80000, interarrivals.length));
    const iaBins = 60;
    const iaMax = iaSample.length ? Math.max(...iaSample) : 1;
    const iaCounts = new Array(iaBins).fill(0);
    for(const v of iaSample){ const idx = Math.min(iaBins-1, Math.floor((v/iaMax)*iaBins)); iaCounts[idx]++; }
    const iaLabels = iaCounts.map((_,i)=> ((i/iaBins)*iaMax).toFixed(3) + '–' + (((i+1)/iaBins)*iaMax).toFixed(3));

    const densityCounts = [];
    for(let i=0;i<iaBins;i++){
      const left = (i/iaBins)*iaMax;
      const right = ((i+1)/iaBins)*iaMax;
      const center = (left+right)/2;
      const width = right-left || 1e-9;
      const dens = lambda * Math.exp(-lambda * center);
      densityCounts.push(dens * iaSample.length * width);
    }

    iaChart.data.labels = iaLabels;
    iaChart.data.datasets = [ { label:'inter-arrivals (freq)', data: iaCounts, backgroundColor:'rgba(66,165,245,0.6)' }, { type:'line', label:'Exp density (scale)', data: densityCounts, borderColor:'#ffffff', borderWidth:1.6, pointRadius:0, fill:false, tension:0.2 } ];
    iaChart.update();

    const meanEmp = finalCounts.reduce((a,b)=>a+b,0)/msize;
    let ss=0; for(let i=0;i<msize;i++){ const d = finalCounts[i]-meanEmp; ss += d*d; }
    const varEmp = (msize>1) ? ss/(msize-1) : 0;

    const chiRes = computeChiSquare(bins.slice(), pmfScaled.slice());
    const kl = klDivergence(bins.slice(), pmf.slice());

    const iaMean = iaSample.length ? iaSample.reduce((a,b)=>a+b,0)/iaSample.length : NaN;
    const iaTheo = 1/Math.max(1e-12, lambda);

    $('report').textContent =
      'Simulation completed — m=' + m + (n?(', n=' + n):'') + ', λ=' + lambda.toFixed(6) + ', T=' + T + '\n' +
      (n?('Δt = ' + (T/n).toExponential(3) + ', p = λΔt ≈ ' + (lambda*(T/n)).toExponential(3) + '\n\n') : '\n') +
      'Final counts N(T):\n' +
      '- Empirical mean = ' + meanEmp.toFixed(6) + '\n' +
      '- Empirical variance = ' + varEmp.toExponential(6) + '\n' +
      '- Theoretical mean (Poisson) = λT = ' + mu.toFixed(6) + '\n' +
      '- Theoretical variance (Poisson) = ' + mu.toFixed(6) + '\n\n' +
      'Quantitative comparison (aggregated chi-square):\n' +
      '- χ² = ' + chiRes.chi2.toFixed(4) + '\n' +
      '- classes after aggregation = ' + chiRes.k + '\n' +
      '- df (λ known) = ' + chiRes.df_known + '\n' +
      '- p-value (df known) = ' + (isNaN(chiRes.pvalue_known)? 'n/a' : chiRes.pvalue_known.toExponential(6)) + '\n' +
      '- df (λ estimated) = ' + chiRes.df_est + '\n' +
      '- p-value (λ estimated) = ' + (isNaN(chiRes.pvalue_est)? 'n/a' : chiRes.pvalue_est.toExponential(6)) + '\n' +
      '- KL divergence (emp||theo) = ' + kl.toExponential(6) + ' (nats)\n\n' +
      'Inter-arrivals (first ' + iaSample.length + ' observations):\n' +
      '- Empirical mean inter-arrival = ' + (isNaN(iaMean)? 'n/a' : iaMean.toFixed(6)) + '\n' +
      '- Theoretical mean inter-arrival (1/λ) = ' + iaTheo.toFixed(6) + '\n\n' +
      'Notes:\n' +
      '- If n is large and p = λT/n is small, Bin(n,p) → Poisson(λT) (law of rare events).\n' +
      '- Inter-arrivals appear exponential; the visual overlap provides a quick goodness-of-fit check.\n' +
      '- The χ² p-values account for aggregation of low-expectation classes; take care if μ is estimated from the sample (reduced df).\n' +
      '- For faster and more exact simulations prefer the inter-arrival method or direct Poisson sampling when possible.\n';

    $('status').textContent = 'Ready';
    lastResult = { m, n, lambda, T, finalCounts: Array.from(finalCounts), interarrivals: iaSample };
  }

  </script>
</body>
</html>
